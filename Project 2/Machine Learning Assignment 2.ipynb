{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 461 Machine Learning Assignment 2\n",
    "### 26 Dec. 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amer Nour Eddin | 213171245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Finding â€“ Is there a path?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally when we are faced with the task of determining whether a given maze has a path or not we resort to various search or path finding algorithms which are able to answer this question with absolute certainty. In this assignment, however, we will take a different approach to solve this problem by building a classifier that determines (to a certain degree) whether a given maze has a path or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ __training_set_positives.p__ : contains 150 mazes that have a path. Each training example in this file has a label of +1.\n",
    "+ __training_set_negatives.p__ : contains 150 mazes that do not have a path. Each training example in this file has a label of -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup for this problem is as follows:\n",
    "\n",
    "+ Your training set has 300 mazes in total\n",
    "\n",
    "\n",
    "+ Each training example is a 2 dimensional array where the green squares are represented as zeros and the black squares are represented as ones.\n",
    "For instance, a given maze could be represented by the following array,\n",
    "[ [0,0,0,1,0,1,0,0], [0,1,0,0,0,1,0,0], [0,0,1,1,0,0,1,1], ...]\n",
    "\n",
    "\n",
    "+ Your training set consists of two dictionaries (one for the positive examples and the other for the negative examples) that have these 2 dimensional arrays as their values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same logic can be applied to the negative examples as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals # To support both python 2 and python 3\n",
    "# import cPickle as pickle # this is for python 2.x\n",
    "import _pickle as pickle # For python 3.x this is the proper way for calling the cPickle \n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_positives = pickle.load(open('training_set_positives.p', 'rb'))\n",
    "train_negatives = pickle.load(open('training_set_negatives.p', 'rb'))\n",
    "\n",
    "\n",
    "# train_positives[100]\n",
    "# train_negatives\n",
    "# cc = np.array(zz)\n",
    "# cc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# a0 = cc[0:2, 0:2]\n",
    "# a1 = cc[0:2, 2:4] \n",
    "# a2 = cc[0:2, 4:6]\n",
    "# a3 = cc[0:2, 6:8]\n",
    "\n",
    "# b0 = cc[2:4, 0:2]\n",
    "# b1 = cc[2:4, 2:4]\n",
    "# b2 = cc[2:4, 4:6]\n",
    "# b3 = cc[2:4, 6:8]\n",
    "\n",
    "# c0 = cc[4:6, 0:2]\n",
    "# c1 = cc[4:6, 2:4]\n",
    "# c2 = cc[4:6, 4:6]\n",
    "# c3 = cc[4:6, 6:8]\n",
    "\n",
    "# d0 = cc[6:8, 0:2]\n",
    "# d1 = cc[6:8, 2:4]\n",
    "# d2 = cc[6:8, 4:6]\n",
    "# d3 = cc[6:8, 6:8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (a0)\n",
    "# print (a1)\n",
    "# print (a2)\n",
    "# print (a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to extract two features from the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first feature you will compute is the proportion of black squares to the total number of squares in the grid. You will write your code for extracting this feature within the function feature1(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second feature you will compute is the sum over all the rows of the maximum number of continuous black squares in each row. You will write your code for extracting this feature within the function feature2(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART a) Feature Extraction\n",
    "def feature1(x):\n",
    "    \"\"\"This feature computes the proportion of black squares to the\n",
    "       total number of squares in the grid.\n",
    "       Parameters\n",
    "       ----------\n",
    "       x: 2-dimensional array representing a maze\n",
    "       Returns\n",
    "       -------\n",
    "       feature1_value: type-float\n",
    "       \"\"\"\n",
    "    N = np.count_nonzero(x) # number of black squares or 1's in x\n",
    "    numrows = len(x) # number of rows in x\n",
    "    numcols = len(x[0]) # number of columns in x\n",
    "    total = numrows*numcols # total number of 1's and 0's in x\n",
    "    feature1_value=N/total # the propotion of 1's in x\n",
    "\n",
    "    return feature1_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(feature1(train_positives[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature2(x):\n",
    "    \"\"\"This feature computes the sum of the max of continuous black squares\n",
    "       in each row\n",
    "       Parameters\n",
    "       ----------\n",
    "       x: 2-dimensional array representing a maze\n",
    "       Returns\n",
    "       -------\n",
    "       feature2_value: type-float\n",
    "       \"\"\"\n",
    "    l = [] # list will contain numbers of continous 1's in each row in x\n",
    "    \n",
    "    for i in x:\n",
    "        count = 0\n",
    "        result = 0\n",
    "        for j in i:\n",
    "            if j == 1:\n",
    "                count += 1\n",
    "            else:\n",
    "                result = max(result, count)\n",
    "                count= 0\n",
    "        l.append(max(result, count))\n",
    "        \n",
    "    f2 = sum(l)\n",
    "\n",
    "    feature2_value=f2\n",
    "    \n",
    "\n",
    "    return feature2_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(feature2(train_negatives[149]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use training_set_positives.p and training_set_negatives.p files to create the training data. You should extract features for each grid in these files and put them into an X matrix and also prepare the corresponding label vector y. Keep the same order in training_set_positives.p and training_set_negatives.p (Put training_set_positives.p examples before training_set_negatives.p examples in the X matrix). X and y should be numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART b) Preparing Data\n",
    "def part_b():\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in train_positives.values():\n",
    "        f1,f2 = feature1(i), feature2(i)\n",
    "        X.append((f1,f2))\n",
    "        y.append(1)\n",
    "    for i in train_negatives.values():\n",
    "        f1,f2 = feature1(i), feature2(i)\n",
    "        X.append((f1,f2))\n",
    "        y.append(0)\n",
    "\n",
    "\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X, y = part_b()\n",
    "# X.shape\n",
    "# X\n",
    "# X.reshape(-1,1)\n",
    "# X.shape\n",
    "# np.array(train_negatives[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Classification with SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will built a SGDClassifier model with parameters random_state=0. Train this model with the training data that you created in part b. Write a function that uses your SGDClassifier to predict whether a maze has a path or not and return 1 or 0, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# PART c) Classification with SGDClassifier\n",
    "\n",
    "X, y = part_b()\n",
    "sgd_clf = SGDClassifier(alpha=0.001, n_iter=20, random_state=0)\n",
    "sgd_clf.fit(X, y)\n",
    "\n",
    "def part_c(x):\n",
    "    \"\"\"\n",
    "       x: 2-dimensional numpy array representing a maze.\n",
    "       output: predicted class (1 or 0).\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    f1, f2 = feature1(x), feature2(x)\n",
    "    ins = np.array([f1, f2]).reshape(1,-1)\n",
    "\n",
    "    predicted_class = sgd_clf.predict(ins)\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd = np.array(train_positives[149])\n",
    "\n",
    "PPP = part_c(asd)\n",
    "# zx = accuracy_score(y, PPP)\n",
    "# zx*100\n",
    "PPP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Assess the performance of the classifier in part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute precision, recall, and confusion matrix for the classifier in part c on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# PART d) Assess the performance of the classifier in part c\n",
    "\n",
    "y_pred = cross_val_predict(sgd_clf, X, y, cv=3)\n",
    "def part_d():\n",
    "    \n",
    "    y_pred = cross_val_predict(sgd_clf, X, y, cv=3)\n",
    "#     y_pred =  part_c(asd)\n",
    "    \n",
    "    precision, recall, confusionmatrix = [precision_score(y, y_pred)], [recall_score(y, y_pred)], [confusion_matrix(y, y_pred)]\n",
    "    return [precision, recall, confusionmatrix]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.87272727272727268], [0.64000000000000001], [array([[136,  14],\n",
       "         [ 54,  96]])]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part_d()\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77333333333333332"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = cross_val_predict(sgd_clf, X, y, cv=3)\n",
    "\n",
    "\n",
    "# ac = accuracy_score(y, y_pred)\n",
    "# ac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Classification with RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat part c with RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# PART e) Classification with RandomForestClassifier\n",
    "\n",
    "X, y = part_b()\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=0)\n",
    "forest_clf.fit(X, y)\n",
    "\n",
    "def part_e(x):\n",
    "    \"\"\"\n",
    "       x: 2-dimensional numpy array representing a maze.\n",
    "       output: predicted class (1 or 0).\n",
    "    \"\"\"\n",
    "    f1, f2 = feature1(x), feature2(x)\n",
    "    ins = np.array([f1, f2]).reshape(1,-1)\n",
    "    \n",
    "    predicted_class = forest_clf.predict(ins)\n",
    "    return predicted_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# asd = np.array(train_positives[4])\n",
    "\n",
    "# print(part_e(asd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Assess the performance of the classifier in part e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute precision, recall, and confusion matrix for the classifier in part e on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART f) Assess the performance of the classifier in part e\n",
    "def part_f():\n",
    "    \n",
    "    y_pred = cross_val_predict(forest_clf, X, y, cv=3)\n",
    "    \n",
    "    \n",
    "    precision, recall, confusionmatrix = [precision_score(y, y_pred)], [recall_score(y, y_pred)], [confusion_matrix(y, y_pred)]\n",
    "    return [precision, recall, confusionmatrix]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.84558823529411764], [0.76666666666666672], [array([[129,  21],\n",
       "         [ 35, 115]])]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part_f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81333333333333335"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cross_val_predict(forest_clf, X, y, cv=3)\n",
    "# ac = accuracy_score(y, y_pred)\n",
    "# ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross_val_score(forest_clf, X, y, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) Your Own Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, prepare your own classifier model with the features of your own, and return the corresponding function as in part c and d. This is the creative part of your assignment where your grade will be determined by how well your classifier works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# this function will create my features\n",
    "def features(x):\n",
    "\n",
    "\n",
    "    a = np.array(x)\n",
    "\n",
    "    l1 = []  # list will contain numbers of continous 0's in each row in x\n",
    "    l2 = [] # list will contain numbers of continous 0's in each column in x\n",
    "    l3 = [] # list will contain numbers of continous 1's in each row in x\n",
    "    l4 = []# list will contain numbers of continous 1's in each column in x\n",
    "\n",
    "    for i in a:\n",
    "        count = 0\n",
    "        result = 0\n",
    "        for j in i:\n",
    "            if j == 0:\n",
    "                count += 1\n",
    "            else:\n",
    "                result = max(result, count)\n",
    "                count= 0\n",
    "        l1.append(max(result, count))\n",
    "\n",
    "    f1 = sum(l1)\n",
    "\n",
    "    for i in a.T:\n",
    "        count = 0\n",
    "        result = 0\n",
    "        for j in i:\n",
    "            if j == 0:\n",
    "                count += 1\n",
    "            else:\n",
    "                result = max(result, count)\n",
    "                count= 0\n",
    "        l2.append(max(result, count))\n",
    "\n",
    "    f2 = sum(l2)\n",
    "\n",
    "    for i in a:\n",
    "        count = 0\n",
    "        result = 0\n",
    "        for j in i:\n",
    "            if j == 1:\n",
    "                count += 1\n",
    "            else:\n",
    "                result = max(result, count)\n",
    "                count= 0\n",
    "        l3.append(max(result, count))\n",
    "\n",
    "    f3 = sum(l3)\n",
    "\n",
    "    for i in a.T:\n",
    "        count = 0\n",
    "        result = 0\n",
    "        for j in i:\n",
    "            if j == 1:\n",
    "                count += 1\n",
    "            else:\n",
    "                result = max(result, count)\n",
    "                count= 0\n",
    "        l4.append(max(result, count))\n",
    "\n",
    "    f4 = sum(l4)\n",
    "    \n",
    "    N = np.count_nonzero(x) # number of all 1's\n",
    "    zeros = 64 - N # number of all 0's\n",
    "    #f1 is the sum over all the rows of the maximum number of continuous 0's in each row\n",
    "    #f2 is the sum over all the columns of the maximum number of continuous 0's in each column\n",
    "    #f3 is the sum over all the rows of the maximum number of continuous 1's in each row\n",
    "    #f4 is the sum over all the columns of the maximum number of continuous 1's in each column\n",
    "\n",
    "    return f1+f2/64, N/64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function will prepare my X and y\n",
    "def prepare():\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in train_positives.values():\n",
    "        f1, f2 = features(i)[0], features(i)[1]\n",
    "        X.append((f1, f2))\n",
    "        y.append(1)\n",
    "    for i in train_negatives.values():\n",
    "        f1, f2 = features(i)[0], features(i)[1]\n",
    "        X.append((f1, f2))\n",
    "        y.append(0)\n",
    "\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# X = prepare()[0] #features\n",
    "# y = prepare()[1] #labels\n",
    "\n",
    "\n",
    "\n",
    "X, y =  prepare()\n",
    "\n",
    "# print(len(X))\n",
    "# print(len(y))\n",
    "\n",
    "# X_trainP, X_testP, y_trainP, y_testP = train_test_split(X[0:149], y[0:149], test_size=0.2, random_state=0)\n",
    "# X_trainN, X_testN, y_trainN, y_testN = train_test_split(X[149:300], y[149:300], test_size=0.2, random_state=0)\n",
    "# print(X_trainP)\n",
    "# print(len(X_trainP))\n",
    "# print(y_trainP)\n",
    "# print(len(y_trainP))\n",
    "# print(X_testP)\n",
    "# print(len(X_testP))\n",
    "# print(y_testP)\n",
    "# print(len(y_testP))\n",
    "\n",
    "# print(X_trainN)\n",
    "# print(len(X_trainN))\n",
    "# print(y_trainN)\n",
    "# print(len(y_trainN))\n",
    "# print(X_testN)\n",
    "# print(len(X_testN))\n",
    "# print(y_testN)\n",
    "# print(len(y_testN))\n",
    "\n",
    "# # X_train = X_trainP + X_trainN\n",
    "# # y_train = y_testP + y_trainN\n",
    "\n",
    "# # X_test = X_testP + X_testN\n",
    "# # y_test = y_testP + y_testN\n",
    "\n",
    "# My_Model = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=4)\n",
    "# My_Model = RandomForestClassifier(random_state=0)\n",
    "# My_Model = SGDClassifier(alpha=0.001, n_iter=20, random_state=0)\n",
    "My_Model = GaussianNB()\n",
    "# My_Model = tree.DecisionTreeClassifier()\n",
    "# My_Model = svm.SVC()\n",
    "# My_Model = svm.LinearSVC()\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
    "\n",
    "# knn_clf = KNeighborsClassifier()\n",
    "# grid_search = GridSearchCV(My_Model, param_grid, cv=5, verbose=3)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "My_Model.fit(X, y)\n",
    "\n",
    "# PART g) Your Own Classification Model\n",
    "def custom_model(x):\n",
    "    \"\"\"\n",
    "       x: 2-dimensional numpy array representing a maze.\n",
    "       output: predicted class (1 or 0).\n",
    "    \"\"\"\n",
    "#     My_Model.fit(X, y)\n",
    "\n",
    "    f1, f2 = features(x)[0], features(x)[1]\n",
    "    ins = np.array([f1, f2]).reshape(1,-1)\n",
    "    predicted_class = My_Model.predict(ins)\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# this function assesses my model as in function in part d\n",
    "def asses_my_model():\n",
    "    \n",
    "    y_pred = cross_val_predict(My_Model, X, y, cv=3)\n",
    "   \n",
    "#     y_pred=My_Model.predict(X)\n",
    "#     print(y_pred)\n",
    "#     print(len(y_pred))\n",
    "    \n",
    "    \n",
    "    precision, recall, confusionmatrix = [precision_score(y, y_pred)], [recall_score(y, y_pred)], [confusion_matrix(y, y_pred)]\n",
    "    return [precision, recall, confusionmatrix]\n",
    "\n",
    "# prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85666666666666669"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(149):\n",
    "# print(custom_model(train_negatives[0]))\n",
    "\n",
    "y_pred = cross_val_predict(My_Model, X, y, cv=3)\n",
    "# # y_pred=My_Model.predict(X)\n",
    "\n",
    "# print(custom_model(train_positives[11]))\n",
    "\n",
    "# accuracy_score(y, y_pred)\n",
    "# # y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0]\n",
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.86896551724137927], [0.83999999999999997], [array([[131,  19],\n",
       "         [ 24, 126]])]]"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asses_my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# cross_val_score(My_Model, X, y, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
