{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 461 Machine Learning Assignment 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 Feb. 2018\n",
    "\n",
    "### Amer Nour Eddin | 213171245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform some basic image recognition tasks. The image dataset we have provided contains images (in jpeg format) of dimensions 120x128, with the training set consisting of 315 images and the test set consisting of 90 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each image, the subject has the following characteristics:\n",
    "    \n",
    "+ Name – name of the subject\n",
    "+ Direction Faced – left, right, straight, up\n",
    "+ Emotion – happy, sad, neutral, angry\n",
    "+ Eyewear – open, sunglasses\n",
    "\n",
    "Each image follows the naming convention “ *name_directionFaced_emotion_eyewear.jpg* ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import _pickle as pickle # For python 3.x this is the proper way for calling the cPickle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction Faced Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X_train using images in the TrainingSet folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image has shape of 120x128. Flatten each image array to a vector of dimensions 1x 15360. Label of the image will be maintained from the file name.\n",
    "\n",
    "Create y_train_ directionfaced using images’ file names. For instance, if the file name is *aaa_right_neutral_eyewear.jpg*, then the label of the image is ‘right’. Use the following dictionary to encode directions into a numerical format:\n",
    "\n",
    "__direction_encode = {'right': 0, 'left': 1, 'up': 2, 'straight': 3}__\n",
    "\n",
    "At the end, X_train will be a numpy array that contains 315 images of dimensions 1x 15360 and y_train_ directionfaced array will contain 315 encoded image labels.\n",
    "\n",
    "Create X_test and y_test_directionfaced arrays using the TestSet folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3,\n",
       "       3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for file in glob.glob('TrainingSet/*.jpg'):\n",
    "    filename = os.path.basename(os.path.normpath(file))\n",
    "    image_array = np.array(Image.open(file).convert('L'))\n",
    "    X.append(image_array.flatten())\n",
    "    \n",
    "\n",
    "for file in glob.glob('TrainingSet/*.jpg'):\n",
    "    filename = os.path.basename(os.path.normpath(file))\n",
    "    namesplit = filename.split(\"_\")\n",
    "    if namesplit[1] == 'right':\n",
    "        y.append(0)\n",
    "    if namesplit[1] == 'left':\n",
    "        y.append(1)\n",
    "    if namesplit[1] == 'up':\n",
    "        y.append(2)\n",
    "    if namesplit[1] == 'straight':\n",
    "        y.append(3)\n",
    "\n",
    "X_train = np.array(X)        \n",
    "y_train_directionfaced = np.array(y)\n",
    "y_train_directionfaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test sets\n",
    "\n",
    "Xt = []\n",
    "yt = []\n",
    "\n",
    "for file in glob.glob('TestSet/*.jpg'):\n",
    "    filename = os.path.basename(os.path.normpath(file))\n",
    "    image_array = np.array(Image.open(file).convert('L'))\n",
    "    Xt.append(image_array.flatten())\n",
    "    \n",
    "\n",
    "for file in glob.glob('TestSet/*.jpg'):\n",
    "    filename = os.path.basename(os.path.normpath(file))\n",
    "    namesplit = filename.split(\"_\")\n",
    "    if namesplit[1] == 'right':\n",
    "        yt.append(0)\n",
    "    if namesplit[1] == 'left':\n",
    "        yt.append(1)\n",
    "    if namesplit[1] == 'up':\n",
    "        yt.append(2)\n",
    "    if namesplit[1] == 'straight':\n",
    "        yt.append(3)\n",
    "\n",
    "X_test = np.array(Xt)        \n",
    "y_test_directionfaced = np.array(yt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.\n",
    "Train a Random Forest classifier (with parameters of random_state=0) on the training dataset and time how long it takes, then evaluate the resulting model on the test set.\n",
    "Return the trained model, time of training, and accuracy on the test set in a pickle format as\n",
    "*part_a.pkl* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "rnd_forest_clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "t0 = time.time()\n",
    "rnd_forest_clf.fit(X, y_train_directionfaced)\n",
    "t1 = time.time()\n",
    "\n",
    "T = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.48s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training took {:.2f}s\".format(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88888888888888884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rnd_forest_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test_directionfaced, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part_a.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_a = [rnd_forest_clf, T, acc]\n",
    "\n",
    "joblib.dump(part_a,'part_a.pkl', protocol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.\n",
    "Use PCA to reduce the training dataset's dimensionality, with an explained variance ratio of 95%. Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster? Return the trained model, time of training, and accuracy on the test set in a pickle format as *part_b.pkl* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd_forest_clf2 = RandomForestClassifier(random_state=42)\n",
    "t0 = time.time()\n",
    "rnd_forest_clf2.fit(X_train_reduced, y_train_directionfaced)\n",
    "t1 = time.time()\n",
    "\n",
    "T = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.20s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training took {:.2f}s\".format(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81111111111111112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "y_pred = rnd_forest_clf2.predict(X_test_reduced)\n",
    "acc = accuracy_score(y_test_directionfaced, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part_b.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_b = [rnd_forest_clf2, T, acc]\n",
    "\n",
    "\n",
    "joblib.dump(part_b, 'part_b.pkl', protocol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will again use X_train and X_test in this part but this time you will use emotion as a label.\n",
    "For instance, if the file name is *aaa_right_neutral_eyewear.jpg*, then the label of the image is ‘neutral’. Create y_train_emotion and t_test_emotion according to emotion label. Use the following dictionary to encode emotions into a numerical format:\n",
    "\n",
    "__emotion_encode = {'neutral': 0, 'happy': 1, 'angry': 2, 'sad': 3}__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 0, 0, 3, 3, 2, 2, 1, 1, 0, 0, 3, 3, 2, 2, 1, 1, 0, 0, 3,\n",
       "       2, 2, 1, 1, 0, 0, 3, 2, 2, 1, 1, 0, 0, 3, 3, 2, 1, 1, 0, 0, 3, 3, 2,\n",
       "       1, 1, 0, 0, 3, 3, 2, 2, 1, 0, 3, 3, 2, 2, 1, 1, 0, 0, 3, 3, 2, 2, 1,\n",
       "       1, 0, 0, 3, 3, 2, 2, 1, 1, 0, 0, 3, 3, 2, 2, 1, 1, 0, 0, 3, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = []\n",
    "yt2 = []\n",
    "\n",
    "for file in glob.glob('TrainingSet/*.jpg'):\n",
    "    filename = os.path.basename(os.path.normpath(file))\n",
    "    namesplit = filename.split(\"_\")\n",
    "    if namesplit[2] == 'neutral':\n",
    "        y2.append(0)\n",
    "    if namesplit[2] == 'happy':\n",
    "        y2.append(1)\n",
    "    if namesplit[2] == 'angry':\n",
    "        y2.append(2)\n",
    "    if namesplit[2] == 'sad':\n",
    "        y2.append(3)\n",
    "\n",
    "for file in glob.glob('TestSet/*.jpg'):\n",
    "    filename = os.path.basename(os.path.normpath(file))\n",
    "    namesplit = filename.split(\"_\")\n",
    "    if namesplit[2] == 'neutral':\n",
    "        yt2.append(0)\n",
    "    if namesplit[2] == 'happy':\n",
    "        yt2.append(1)\n",
    "    if namesplit[2] == 'angry':\n",
    "        yt2.append(2)\n",
    "    if namesplit[2] == 'sad':\n",
    "        yt2.append(3)\n",
    "\n",
    "y_train_emotion = np.array(y2)\n",
    "y_test_emotion = np.array(yt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.\n",
    "Train a Logistic Regression classifier (with parameters of multi_class=\"multinomial\", solver=\"lbfgs\", random_state=0) on the training dataset and time how long it takes, then evaluate the resulting model on the test set. Return the trained model, time of training, and accuracy on the test set in a pickle format as *part_c.pkl* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=0)\n",
    "t0 = time.time()\n",
    "log_clf.fit(X_train, y_train_emotion)\n",
    "t1 = time.time()\n",
    "\n",
    "T = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 6.77s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training took {:.2f}s\".format(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test_emotion, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part_c.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_c = [log_clf, T, acc]\n",
    "\n",
    "joblib.dump(part_c, 'part_c.pkl', protocol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d.\n",
    "Use PCA to reduce the training dataset's dimensionality, with an explained variance ratio of 95%. Train a new Logistic Regression classifier on the reduced dataset and see how long it takes. Was training much faster? Return the trained model, time of training, and accuracy on the test set in a pickle format as *part_d.pkl* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_clf2 = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "t0 = time.time()\n",
    "log_clf2.fit(X_train_reduced, y_train_emotion)\n",
    "t1 = time.time()\n",
    "\n",
    "T = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.28s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training took {:.2f}s\".format(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29999999999999999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_clf2.predict(X_test_reduced)\n",
    "acc = accuracy_score(y_test_emotion, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part_d.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_d = [log_clf2, T, acc]\n",
    "\n",
    "joblib.dump(part_d, 'part_d.pkl', protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
